@article{SHI2020105618,
  abstract   = {E-learners face a large amount of fragmented learning content during e-learning. How to extract and organize this learning content is the key to achieving the established learning target, especially for non-experts. Reasonably arranging the order of the learning objects to generate a well-defined learning path can help the e-learner complete the learning target efficiently and systematically. Currently, knowledge-graph-based learning path recommendation algorithms are attracting the attention of researchers in this field. However, these methods only connect learning objects using single relationships, which cannot generate diverse learning paths to satisfy different learning needs in practice. To overcome this challenge, this paper proposes a learning path recommendation model based on a multidimensional knowledge graph framework. The main contributions of this paper are as follows. Firstly, we have designed a multidimensional knowledge graph framework that separately stores learning objects organized in several classes. Then, we have proposed six main semantic relationships between learning objects in the knowledge graph. Secondly, a learning path recommendation model is designed for satisfying different learning needs based on the multidimensional knowledge graph framework, which can generate and recommend customized learning paths according to the e-learner's target learning object. The experiment results indicate that the proposed model can generate and recommend qualified personalized learning paths to improve the learning experiences of e-learners.},
  author     = {Daqian Shi and Ting Wang and Hao Xing and Hao Xu},
  doi        = {https://doi.org/10.1016/j.knosys.2020.105618},
  issn       = {0950-7051},
  journal    = {Knowledge-Based Systems},
  keywords   = {Learning path recommendation, Knowledge graph, e-learning, Learning needs},
  pages      = {105618},
  title      = {A learning path recommendation model based on a multidimensional knowledge graph framework for e-learning},
  url        = {https://www.sciencedirect.com/science/article/pii/S095070512030085X},
  volume     = {195},
  year       = {2020},
  bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S095070512030085X},
  bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2020.105618}
}

@inproceedings{wang2020neural,
  title     = {Neural cognitive diagnosis for intelligent education systems},
  author    = {Wang, Fei and Liu, Qi and Chen, Enhong and Huang, Zhenya and Chen, Yuying and Yin, Yu and Huang, Zai and Wang, Shijin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {34},
  pages     = {6153--6161},
  year      = {2020}
}

@inproceedings{sakt2019,
  title     = {A self-attentive model for knowledge tracing},
  author    = {Shalini Pandey and George Karypis},
  year      = {2019},
  series    = {EDM 2019 - Proceedings of the 12th International Conference on Educational Data Mining},
  publisher = {International Educational Data Mining Society},
  pages     = {384--389}
}

@misc{devlin2019bert,
  title         = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year          = {2019},
  eprint        = {1810.04805},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{Ma2019MCDM,
  author   = {Ma, Wenchao and Guo, Wenjing},
  title    = {Cognitive diagnosis models for multiple strategies},
  journal  = {British Journal of Mathematical and Statistical Psychology},
  volume   = {72},
  number   = {2},
  pages    = {370-392},
  keywords = {cognitive diagnosis, diagnostic classification, item response, multiple strategy, psychometric},
  doi      = {https://doi.org/10.1111/bmsp.12155},
  url      = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/bmsp.12155},
  eprint   = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bmsp.12155},
  abstract = {Cognitive diagnosis models (CDMs) have been used as psychometric tools in educational assessments to estimate students’ proficiency profiles. However, most CDMs assume that all students adopt the same strategy when approaching problems in an assessment, which may not be the case in practice. This study develops a generalized multiple-strategy CDM for dichotomous response data. The proposed model provides a unified framework to accommodate various condensation rules (e.g., conjunctive, disjunctive, and additive) and different strategy selection approaches (i.e., probability-matching, over-matching, and maximizing). Model parameters are estimated using the marginal maximum likelihood estimation via expectation-maximization algorithm. Simulation studies showed that the parameters of the proposed model can be adequately recovered and that the proposed model was relatively robust to some types of model misspecifications. A set of real data was analysed as well to illustrate the use of the proposed model in practice.},
  year     = {2019}
}

@article{Lee2019CreatingAN,
  title   = {Creating A Neural Pedagogical Agent by Jointly Learning to Review and Assess},
  author  = {Y. Lee and Youngduck Choi and Jung-hyun Cho and Alexander R. Fabbri and Hyunbin Loh and Chanyou Hwang and Yongku Lee and Sang-Wook Kim and Dragomir R. Radev},
  journal = {ArXiv},
  year    = {2019},
  volume  = {abs/1906.10910}
}


@inproceedings{DRE2019Huang,
  author    = {Huang, Zhenya and Liu, Qi and Zhai, Chengxiang and Yin, Yu and Chen, Enhong and Gao, Weibo and Hu, Guoping},
  title     = {Exploring Multi-Objective Exercise Recommendations in Online Education Systems},
  year      = {2019},
  isbn      = {9781450369763},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3357384.3357995},
  doi       = {10.1145/3357384.3357995},
  abstract  = {Recommending suitable exercises to students in an online education system is highly useful. Existing approaches usually rely on machine learning techniques to mine large amounts of student interaction log data accumulated in the systems to select the most suitable exercises for each student. Generally, they mainly aim to optimize a single objective, i.e., recommending non-mastered exercises to address the immediate weakness of students. While this is a reasonable objective, there exist more beneficial multiple objectives in the long-term learning process that need to be addressed including Review &amp; Explore, Smoothness of difficulty level and Engagement. In this paper, we propose a novel Deep Reinforcement learning framework, namely DRE, for adaptively recommending Exercises to students with optimization of above three objectives. In the framework, we propose two different Exercise Q-Networks for the agent, i.e., EQNM and EQNR, to generate recommendations following Markov property and Recurrent manner, respectively. We also propose novel reward functions to formally quantify those three objectives so that DRE could update and optimize its recommendation strategy by interactively receiving students' performance feedbacks (e.g., score). We conduct extensive experiments on two real-world datasets. Experimental results clearly show that the proposed DRE can effectively learn from the student interaction data to optimize multiple objectives in a single unified framework and adaptively recommend suitable exercises to students.},
  booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages     = {1261-1270},
  numpages  = {10},
  keywords  = {deep reinforcement learning, recommendation, multiple objectives},
  location  = {Beijing, China},
  series    = {CIKM '19}
}

@inproceedings{nakagawa2019graph,
  author       = {Nakagawa, Hiromi and Iwasawa, Yusuke and Matsuo, Yutaka},
  booktitle    = {2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
  organization = {IEEE},
  pages        = {156--163},
  title        = {Graph-based knowledge tracing: modeling student proficiency using graph neural network},
  year         = {2019}
}

@article{guo2019improving,
  title     = {Improving text classification with weighted word embeddings via a multi-channel TextCNN model},
  author    = {Guo, Bao and Zhang, Chunxia and Liu, Junmin and Ma, Xiaoyi},
  journal   = {Neurocomputing},
  volume    = {363},
  pages     = {366--374},
  year      = {2019},
  publisher = {Elsevier}
}


@inproceedings{9064104,
  author    = {Cai, Dejun and Zhang, Yuan and Dai, Bintao},
  booktitle = {2019 IEEE 5th International Conference on Computer and Communications (ICCC)},
  title     = {Learning Path Recommendation Based on Knowledge Tracing Model and Reinforcement Learning},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {1881-1885},
  doi       = {10.1109/ICCC47050.2019.9064104}
}
@article{chinese-bert-wwm,
  title   = {Pre-Training with Whole Word Masking for Chinese BERT},
  author  = {Cui, Yiming and Che, Wanxiang and Liu, Ting and Qin, Bing and Yang, Ziqing and Wang, Shijin and Hu, Guoping},
  journal = {arXiv preprint arXiv:1906.08101},
  year    = {2019}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal = {arXiv preprint arXiv:1706.03762},
  year    = {2017}
}

@inproceedings{joulin-etal-2017-bag,
  title     = {Bag of Tricks for Efficient Text Classification},
  author    = {Joulin, Armand  and
      Grave, Edouard  and
      Bojanowski, Piotr  and
      Mikolov, Tomas},
  booktitle = {Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
  month     = apr,
  year      = {2017},
  address   = {Valencia, Spain},
  publisher = {Association for Computational Linguistics},
  pages     = {427--431}
}

@inproceedings{zhang2017dynamic,
  author    = {Zhang, Jiani and Shi, Xingjian and King, Irwin and Yeung, Dit-Yan},
  booktitle = {Proceedings of the 26th international conference on World Wide Web},
  pages     = {765--774},
  title     = {Dynamic key-value memory networks for knowledge tracing},
  year      = {2017}
}

@article{chen2017improving,
  title     = {Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN},
  author    = {Chen, Tao and Xu, Ruifeng and He, Yulan and Wang, Xuan},
  journal   = {Expert Systems with Applications},
  volume    = {72},
  pages     = {221--230},
  year      = {2017},
  publisher = {Elsevier}
}

@inproceedings{zhou2016attention,
  author    = {Zhou, Peng and Shi, Wei and Tian, Jun and Qi, Zhenyu and Li, Bingchen and Hao, Hongwei and Xu, Bo},
  booktitle = {Proceedings of the 54th annual meeting of the association for computational linguistics (volume 2: Short papers)},
  pages     = {207--212},
  title     = {Attention-based bidirectional long short-term memory networks for relation classification},
  year      = {2016}
}

@article{kipf2016semi,
  author  = {Kipf, Thomas N and Welling, Max},
  journal = {arXiv preprint arXiv:1609.02907},
  title   = {Semi-supervised classification with graph convolutional networks},
  year    = {2016}
}

@article{piech2015deep,
  author  = {Piech, Chris and Bassen, Jonathan and Huang, Jonathan and Ganguli, Surya and Sahami, Mehran and Guibas, Leonidas J and Sohl-Dickstein, Jascha},
  journal = {Advances in neural information processing systems},
  pages   = {505--513},
  title   = {Deep knowledge tracing},
  volume  = {28},
  year    = {2015}
}

@inproceedings{yudelson2013individualized,
  author       = {Yudelson, Michael V and Koedinger, Kenneth R and Gordon, Geoffrey J},
  booktitle    = {International conference on artificial intelligence in education},
  organization = {Springer},
  pages        = {171--180},
  title        = {Individualized bayesian knowledge tracing models},
  year         = {2013}
}

@article{segev2009context,
  title     = {Context-based matching and ranking of web services for composition},
  author    = {Segev, Aviv and Toch, Eran},
  journal   = {IEEE Transactions on Services Computing},
  volume    = {2},
  number    = {3},
  pages     = {210--222},
  year      = {2009},
  publisher = {IEEE}
}

@misc{gcngithub,
  note   = {\url{https://github.com/tkipf/gcn} Accessed March 1, 2021},
  title  = {Graph Convolutional Networks},
  author = {tkipf}
}


@misc{wwmbertgithub,
  author       = {Cui, Yiming and Che, Wanxiang and Liu, Ting and Qin, Bing and Yang, Ziqing and Wang, Shijin and Hu, Guoping},
  title        = {中文BERT-wwm},
  howpublished = {\url{https://github.com/tkipf/gcn}}
}